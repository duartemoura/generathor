{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e5adef-25ea-4247-af21-aece29e30b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the current working directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed37acd-a3bc-42c3-9d1c-46d6714a237a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/src\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fc55866-a7ff-40fd-b232-32f65c519af0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m170.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb046e48-dedc-4722-bc0d-09d1f812faad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:02:15,337 - botocore.credentials - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/src/embeddings/embedding_manager.py:12: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockEmbeddings``.\n",
      "  self.embeddings = BedrockEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import boto3\n",
    "import src\n",
    "from src.document_processor.loader import DocumentLoader\n",
    "from src.document_processor.chunker import DocumentChunker\n",
    "from src.document_processor.cleaner import TextCleaner\n",
    "from src.embeddings.embedding_manager import EmbeddingManager\n",
    "from src.question_generation.generator import EnhancedQuestionGenerator\n",
    "import logging\n",
    "\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, config['logging']['level']),\n",
    "    format=config['logging']['format']\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize AWS client\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Initialize components\n",
    "loader = DocumentLoader()\n",
    "chunker = DocumentChunker(\n",
    "    chunk_size=config['document_processing']['chunk_size'],\n",
    "    chunk_overlap=config['document_processing']['chunk_overlap']\n",
    ")\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "embedding_manager = EmbeddingManager(\n",
    "    bedrock_client,\n",
    "    model_id=config['embedding']['model_id']\n",
    ")\n",
    "\n",
    "generator = EnhancedQuestionGenerator(\n",
    "    llm_client=bedrock_client,\n",
    "    model_id=config['question_generation']['model_id'],\n",
    "    embedding_manager=embedding_manager,\n",
    "    max_tokens=config['question_generation']['max_tokens'],\n",
    "    temperature=config['question_generation']['temperature']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0386b-19bd-4f54-aebb-08cdae279a28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:13:01,778 - __main__ - INFO - Documents loaded\n",
      "2024-11-08 11:13:01,927 - __main__ - INFO - Documents cleaned\n",
      "2024-11-08 11:13:02,374 - __main__ - INFO - Documents chunked into 2167 chunks\n"
     ]
    }
   ],
   "source": [
    "# Process documents\n",
    "documents = loader.load_document(\"/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/Physics_NuclMed.pdf\")\n",
    "logger.info(\"Documents loaded\")\n",
    "\n",
    "# Clean and chunk documents\n",
    "cleaned_documents = []\n",
    "for doc in documents:\n",
    "    doc.page_content = cleaner.clean_text(doc.page_content)\n",
    "    cleaned_documents.append(doc)\n",
    "logger.info(\"Documents cleaned\")\n",
    "\n",
    "chunks = chunker.chunk_documents(cleaned_documents)\n",
    "logger.info(f\"Documents chunked into {len(chunks)} chunks\")\n",
    "\n",
    "# Create embeddings\n",
    "embedding_manager.create_embeddings(chunks)\n",
    "logger.info(\"Embeddings created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5e19bd-3b20-4e4b-8329-33dcdbf08c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:02:35,335 - __main__ - INFO - 3 question-answer pairs generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the objective of this project?\n",
      "Answer 1: The objective of this project is to improve an automatic image segmentation system applied to retinal images by testing various preprocessing, segmentation, and post-processing techniques to enhance segmentation accuracy.\n",
      "\n",
      "Question 2: What performance metric is used to evaluate the effectiveness of the different approaches?\n",
      "Answer 2: The project evaluates the effectiveness of each approach using the Jaccard Index (IoU) as the performance metric.\n",
      "\n",
      "Question 3: What was the baseline technique used for retinal image segmentation and its performance (IoU)?\n",
      "Answer 3: The baseline technique was a threshold-based segmentation method involving preprocessing steps like Gaussian smoothing, illumination compensation, and contrast enhancement, followed by thresholding and small-object removal to isolate retinal structures. Its performance, measured by the Jaccard (IoU) metric, was 0.340 ± 0.036.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Generate questions\n",
    "questions = generator.generate_questions_from_docs(\n",
    "    chunks,\n",
    "    num_questions=100\n",
    ")\n",
    "logger.info(f\"{len(questions)} question-answer pairs generated\")\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "qa_data = [{\"Question\": qa.question, \"Answer\": qa.answer} for qa in questions]\n",
    "\n",
    "# Create DataFrame\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9041c4fb-8e17-4244-bcdb-8a285196016b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:10:29,338 - __main__ - INFO - Chunked into 17 chunks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: Biomedical Image Segmentation for Retinal Images Universidad Carlos III de Madrid Duarte Pinto Correia de Moura Guillermo Rey Paniagua Masters in Machine Learning for Health October 28, 2024 This project aims to improve an automatic image segmentation system applied to retinal images. Various preprocessing, segmentation, and post-processing techniques are tested to enhance segmentation accuracy. The project evaluates the effectiveness of each approach using the Jaccard Index (IoU) as the performance metric.\n",
      "Chunk 2: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report 1 Introduction This report explores biomedical image segmentation techniques applied to retinal images with the objective of improving upon a baseline system provided by Professor Fernando. The baseline system utilized a threshold-based segmentation method involving preprocessing steps like Gaussian smoothing, illumination compensation, and contrast enhancement, followed by thresholding and small-object removal to isolate retinal structures. Our goal is to enhance this system to maximize the Jaccard score (IoU). 2 Results 2.1 Performance Comparison Table 1 summarizes the performance of each technique applied to improve the baseline results, represented by the Jaccard (IoU) metric. Table 1: Performance (IoU) of Segmentation Techniques Technique Description IoU Baseline Threshold-Based Segmentation 0.340  0.036 Method 1 Illumination Compensation with Median Filter and stronger denoising 0.544  0.065\n",
      "Chunk 3: (IoU) of Segmentation Techniques Technique Description IoU Baseline Threshold-Based Segmentation 0.340  0.036 Method 1 Illumination Compensation with Median Filter and stronger denoising 0.544  0.065 Method 2 Removal of Small Objects 0.544  0.063 Method 3 Higher Blurring and CLAHE 0.561  0.058 Method 4 Enhanced Contrast with Adaptive Masking 0.568  0.057 Method 5 Refined Masking with Adjusted Thresholding 0.571  0.056 Method 6 Moderate Blurring with Enhanced Illumination 0.554  0.062 Method 7 Vessel Enhancement with Frangi Filter 0.578  0.056 Method 8 Frangi Filter with Enhanced Post-Processing 0.577  0.056 2.2 Technique Descriptions In order to describe the procedures, we will call the names of the functions when necessary. Also, only the changes with respect to any former method are commented. 2.2.1 Baseline: Illumination Compensation through Gaussian Filter with Otsu Pre-processing: We converted to grayscale and applied Gaussian blur (getting_retina_mask). We corrected illumi-\n",
      "Chunk 4: commented. 2.2.1 Baseline: Illumination Compensation through Gaussian Filter with Otsu Pre-processing: We converted to grayscale and applied Gaussian blur (getting_retina_mask). We corrected illumi- nation with a Gaussian filter (illumination_compensation) and enhanced contrast with histogram equalization (con- trast_enhancement). Segmentation: We used Otsus thresholding (th_based_segmentation) within the retina mask [ 1]. Post-processing: We removed small objects (remove_small_objects). This method achieved an IoU of 0.340. 2.2.2 Technique #1: Illumination Compensation with Median Filter and Stronger Denoising Pre-processing: We used a larger sigma in the Gaussian filter (getting_retina_mask) for better denoising and replaced the Gaussian filter with a median filter (illumination_compensation) and a large kernel to keep only the illumination patterns. These changes improved vessel visibility, increasing the IoU to 0.541. 2.2.3 Technique #2: Improvement of Technique #1 through Removal\n",
      "Chunk 5: and a large kernel to keep only the illumination patterns. These changes improved vessel visibility, increasing the IoU to 0.541. 2.2.3 Technique #2: Improvement of Technique #1 through Removal of Small Objects Post-processing: We refined the final step by removing smaller noise (remove_small_objects), preserving small vessels that were eliminated in Technique #1. This led to a slight IoU improvement to 0.544. 2.2.4 Technique #3: Higher Blurring, Stronger Illumination Removal, and CLAHE Pre-processing: We increased the Gaussian blur sigma (getting_retina_mask) for better smoothing, applied a double median filter (illumination_compensation) for even stronger illumination removal, and used CLAHE (contrast_enhancement) for local contrast enhancement to find even the smallest vessels. These adjustments improved the IoU to 0.561. Page 1\n",
      "Chunk 6: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report 2.2.5 Technique #4: Enhanced Contrast with Adaptive Masking Post-processing: We removed larger structures due to noise introduced by CLAHE, as the drawback of CLAHE is that it also enhances local noise. This led to better isolation of retinal structures and an IoU of 0.568. 2.2.6 Technique #5: Refined Masking with Adjusted Thresholding Pre-processing: We applied a slightly reduced threshold (99% of Otsu value) in getting_retina_mask to increase the area of the retinal region mask, and used a smaller median filter (illumination_compensation) to enhance local contrast. This improved the IoU to 0.571. 2.2.7 Technique #6: Moderate Blurring with Enhanced Illumination Removal Pre-processing: We used moderate Gaussian blur (sigma = 9) in getting_retina_mask and a larger median filter (sigma = 15) in illumination_compensation to further reduce the effect of light and noise in the retinal segmentation. This\n",
      "Chunk 7: Gaussian blur (sigma = 9) in getting_retina_mask and a larger median filter (sigma = 15) in illumination_compensation to further reduce the effect of light and noise in the retinal segmentation. This method resulted in an IoU of 0.554, slightly less effective than Techniques #4 and #5. 2.2.8 Technique #7: Vessel Enhancement with Frangi Filter Segmentation: We applied the Frangi filter (th_based_segmentation) to enhance vessel tubular structures and adapted thresholds [ 2,3].Post-processing: We introduced morphological dilation and removed small objects to reduce noise. This technique achieved an IoU of 0.578. 2.2.9 Technique #8: Frangi Filter with Enhanced Post-Processing Post-processing: We applied additional morphological closing and dilation after Frangi enhancement to fill gaps and enhance vessel continuity. The IoU remained similar at 0.577, indicating a practical upper-bound. 3 Discussion After evaluating 9 different approaches, it is clear that each methodology has its\n",
      "Chunk 8: and enhance vessel continuity. The IoU remained similar at 0.577, indicating a practical upper-bound. 3 Discussion After evaluating 9 different approaches, it is clear that each methodology has its advantages and disadvantages. There is always a tradeoff between keeping small vessels, and thus, some noise; or keeping only the large vessels and, at the same time, removing all small components, including vessels. None of these approaches efficiently segments the images perfectly, but there is still a significant improvement from the baseline output to the best one. The results were improved from a Jaccard Score of 0.340 to 0.578 [4, 5]. 3.1 Unsuccessful Approaches Incorporating a Canny edge detector in the preprocessing pipeline was attempted. Despite producing clear edges after adaptive histogram equalization and Gaussian smoothing, filling the spaces between edges was challenging. Incomplete edge closures led to unintended background filling during morphological operations, making\n",
      "Chunk 9: histogram equalization and Gaussian smoothing, filling the spaces between edges was challenging. Incomplete edge closures led to unintended background filling during morphological operations, making edge detection unsuitable for segmentation when structures are not fully connected. Consequently, this method was discarded. Another approach that was considered was to use registration to segment images. In other words, we could have used the best individual output mask from Technique #7 and, through the usage of SimpleElastix, performed a non-linear registration with respect to the other images [ 6]. However, as some retinal images include vessels even on the corners, that task would have been extremely difficult. Therefore, we discarded it. Dividing the retina image into three color components and processing each separately is counterproductive because the vessels prominence is reduced in some channels. Thus, this option was ruled out. 3.2 Conclusion This study significantly improved\n",
      "Chunk 10: and processing each separately is counterproductive because the vessels prominence is reduced in some channels. Thus, this option was ruled out. 3.2 Conclusion This study significantly improved retinal vessel segmentation, increasing the IoU score from 0.340 to 0.578. Techniques like Gaussian blurring and CLAHE enhanced contrast, while median filtering reduced noise and preserved edges. The Frangi filter, optimized for tubular structures, achieved the highest IoU scores when combined with morphological post-processing. Combining vessel-specific filters, adaptive contrast enhancement, and morphological operations proved most effective. Future work could explore deep learning approaches or further optimize filtering parameters to enhance performance. Page 2\n",
      "Chunk 11: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report References [1]N. Otsu, A threshold selection method from gray-level histograms, IEEE Transactions on Systems, Man, and Cybernetics , vol. 9, no. 1, pp. 6266, 1979. [2]A. F. Frangi, W. J. Niessen, K. L. Vincken, and M. A. Viergever, Multiscale vessel enhancement filtering, in International Conference on Medical Image Computing and Computer-Assisted Intervention . Springer, 1998, pp. 130137. [3]W. Fu, K. Breininger, T. Wrfl, N. Ravikumar, R. Schaffert, and A. Maier, Frangi-net: A neural network approach to vessel segmentation, Journal Name , 2022. [4]J. Almotiri, K. Elleithy, and A. Elleithy, Retinal vessels segmentation techniques and algorithms: A survey, Journal Name , 2020. [5]A. Khandouzi, A. Ariafar, Z. Mashayekhpour, M. Pazira, and Y . Baleghi, Retinal vessel segmentation, a review of classic and deep methods, Journal Name , 2021. [6]K. Marstal et al., Simpleelastix: A user-friendly,\n",
      "Chunk 12: A. Ariafar, Z. Mashayekhpour, M. Pazira, and Y . Baleghi, Retinal vessel segmentation, a review of classic and deep methods, Journal Name , 2021. [6]K. Marstal et al., Simpleelastix: A user-friendly, multi-lingual library for medical image registration, 2016. [Online]. Available: https://simpleelastix.readthedocs.io/ Page 3\n",
      "Chunk 13: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report Annex: Graphical Summary of the Work This annex presents a sequence of images illustrating the evolution of the retinal image through our segmentation pipeline, highlighting the effect and contribution of each proposed technique. Figure 1: Output after each step using Baseline Technique #1 Figure 2: Output after each step using Technique 1 Page 4\n",
      "Chunk 14: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report Technique #2 Figure 3: Output after each step using Technique 2 Technique #3 Figure 4: Output after each step using Technique 3 Page 5\n",
      "Chunk 15: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report Technique #4 Figure 5: Output after each step using Technique 4 Technique #5 Figure 6: Output after each step using Technique 5 Page 6\n",
      "Chunk 16: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report Technique #6 Figure 7: Output after each step using Technique 6 Technique #7 Figure 8: Output after each step using Technique 7 Page 7\n",
      "Chunk 17: Duarte Pinto Correia de Moura, Guillermo Rey Paniagua Retina Segmentation Project Report Technique #8 Figure 9: Output after each step using Technique 8 Page 8\n"
     ]
    }
   ],
   "source": [
    "chunks = chunker.chunk_documents(cleaned_documents)\n",
    "logger.info(f\"Chunked into {len(chunks)} chunks.\")\n",
    "\n",
    "for idx, chunk in enumerate(chunks, start=1):\n",
    "    print(f\"Chunk {idx}: {chunk.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc10b5-c088-4608-bc8c-e071d000d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
