{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44629b8-b3c9-4783-8741-613656661bd9",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07439da-c162-4d6b-b6da-41f63b9a8680",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f45f4-0ce5-4d70-8716-a536e8adbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install faiss-gpu\n",
    "!pip install peft\n",
    "!pip install transformers\n",
    "!pip install ragas\n",
    "!pip install llama_index\n",
    "!pip install langchain-aws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9ee5771-c8b4-4bdf-8e78-bcc1f8ac9617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import yaml\n",
    "import boto3\n",
    "import src\n",
    "from src.document_processor.loader import DocumentLoader\n",
    "from src.document_processor.chunker import DocumentChunker\n",
    "from src.document_processor.cleaner import TextCleaner\n",
    "from src.embeddings.embedding_manager import EmbeddingManager\n",
    "from src.question_generation.generator import EnhancedQuestionGenerator\n",
    "import logging\n",
    "\n",
    "\n",
    "# Initialize a session using the default profile or environment credentials\n",
    "session = boto3.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb046e48-dedc-4722-bc0d-09d1f812faad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, config['logging']['level']),\n",
    "    format=config['logging']['format']\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize AWS client\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Initialize components\n",
    "loader = DocumentLoader()\n",
    "chunker = DocumentChunker(\n",
    "    chunk_size=config['document_processing']['chunk_size'],\n",
    "    chunk_overlap=config['document_processing']['chunk_overlap']\n",
    ")\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "embedding_manager = EmbeddingManager(\n",
    "    bedrock_client,\n",
    "    model_id=config['embedding']['model_id']\n",
    ")\n",
    "\n",
    "generator = EnhancedQuestionGenerator(\n",
    "    llm_client=bedrock_client,\n",
    "    model_id=config['question_generation']['model_id'],\n",
    "    embedding_manager=embedding_manager,\n",
    "    max_tokens=config['question_generation']['max_tokens'],\n",
    "    temperature=config['question_generation']['temperature']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0386b-19bd-4f54-aebb-08cdae279a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process documents\n",
    "documents = loader.load_document(\"/home/ec2-user/SageMaker/Fine_Tune_LLMs/Big/data/NM_changed.pdf\")\n",
    "logger.info(\"Documents loaded\")\n",
    "\n",
    "# Clean and chunk documents\n",
    "cleaned_documents = []\n",
    "for doc in documents:\n",
    "    doc.page_content = cleaner.clean_text(doc.page_content)\n",
    "    cleaned_documents.append(doc)\n",
    "logger.info(\"Documents cleaned\")\n",
    "\n",
    "chunks = chunker.chunk_documents(cleaned_documents)\n",
    "logger.info(f\"Documents chunked into {len(chunks)} chunks\")\n",
    "\n",
    "# Create embeddings\n",
    "embedding_manager.create_embeddings(chunks)\n",
    "logger.info(\"Embeddings created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c86859-442d-438f-8ee5-a6baecfe353e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create embeddings and save them\n",
    "#embedding_manager.create_embeddings(documents)\n",
    "embedding_manager.save_embeddings(\"faiss_index\", \"metadata.txt\")\n",
    "\n",
    "# Load the saved embeddings\n",
    "#embedding_manager.load_embeddings(\"faiss_index\")\n",
    "\n",
    "# Wipe the existing database\n",
    "#embedding_manager.wipe_embeddings(\"faiss_index\", \"metadata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e19bd-3b20-4e4b-8329-33dcdbf08c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Generate questions\n",
    "questions = generator.generate_questions_from_docs(\n",
    "    chunks,\n",
    "    num_questions= 100\n",
    ")\n",
    "logger.info(f\"{len(questions)} question-answer pairs generated\")\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "qa_data = [{\"Question\": qa.question, \"Answer\": qa.answer, \"Context\": qa.context} for qa in questions]\n",
    "\n",
    "# Create DataFrame\n",
    "qa_df = pd.DataFrame(qa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3e99d-1e39-4928-8333-25bb6754dd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2fe6b-daf5-47ba-abad-53cd039426db",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df.to_csv(\"qa_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e5034-231b-4b45-9fe8-99185a34a0bf",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fefaf6-37b6-4a56-be64-a01bebc8fbd9",
   "metadata": {},
   "source": [
    "## Ministral-3B-instruct\n",
    "\n",
    "I'm going to test this model on really specific questions from the Nuclear Medicine manual and see how well it responds firs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ff7f4-a0cd-4ce0-b36b-af5fb3368f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "!pip install ragas\n",
    "!pip install llama_index\n",
    "import torch\n",
    "import ragas\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from ragas.testset import TestsetGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import gc\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Memory management class\n",
    "class MemoryTracker:\n",
    "    def __init__(self):\n",
    "        self.records = []\n",
    "    \n",
    "    def log_memory(self, checkpoint):\n",
    "        memory_stats = {\n",
    "            'checkpoint': checkpoint,\n",
    "            'allocated': torch.cuda.memory_allocated() / 1024**2,\n",
    "            'reserved': torch.cuda.memory_reserved() / 1024**2\n",
    "        }\n",
    "        self.records.append(memory_stats)\n",
    "        return memory_stats\n",
    "\n",
    "    def clear_memory(self):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "memory_tracker = MemoryTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b83be09-c8a0-4cd3-95d5-4dffca916ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "# Run garbage collector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e874e7e-bd71-4b74-85a1-5c44a910e944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "def print_gpu_memory():\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f45104-1318-40db-93a5-698a732a0b39",
   "metadata": {},
   "source": [
    "## Generating answers based on the questions generated by Claude in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a338da-5abd-434f-aa60-0dd9d0b82dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5396510352a4e32973d666365b9911f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47260672ab984aee969fbeb5ec275fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba60d2bedaec48cb9bf4f90422f0d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9e09c2195744bc935ffaee37ed258a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/2.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e71239e6d3747cfb44b4ff2ee4d6908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/2.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c52b3ef5be241e0a42181a40517868b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/698M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17090d2bcdb94e5ea07364e736385154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9c8f9f870041f6980caf7929c9d753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8036dbad3154751825dc367e9834891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679091d98b9b47cbac7dc0943871a5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157fc7410a0748fb84cb2dfe9fe43764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/510 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load questions from the CSV\n",
    "qa_df = pd.read_csv(\"qa_data.csv\")  # Replace with your CSV file path\n",
    "questions = qa_df['Question'].tolist()  # Assuming 'question' is the column name\n",
    "\n",
    "# Initialize the Mistral model pipeline\n",
    "pipe = pipeline(\"text-generation\", model=\"ministral/Ministral-3b-instruct\", device = 0)\n",
    "\n",
    "responses = []\n",
    "for question in questions:\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    response = pipe(messages, max_new_tokens=600, do_sample=True, temperature = 0.4, top_p = 0.7)\n",
    "\n",
    "    # Navigate the nested structure to extract the assistant's content\n",
    "    try:\n",
    "        generated_messages = response[0]['generated_text']\n",
    "        assistant_message = next(\n",
    "            (msg['content'] for msg in generated_messages if msg['role'] == 'assistant'), \n",
    "            \"No assistant response found\"\n",
    "        )\n",
    "        responses.append(assistant_message)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} in response {response}\")\n",
    "        responses.append(\"Error: Unexpected response format\")\n",
    "\n",
    "# Combine questions and responses\n",
    "result_df = pd.DataFrame({'question': questions, 'mistral_response': responses})\n",
    "\n",
    "# Save the results to a new CSV\n",
    "result_df .to_csv(\"qa_with_mistral_responses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a27464ba-04f3-4af1-9d78-33887bdcc812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv(\"qa_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "753df524-ade3-4b6a-bda5-fe3394ebeaf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the fundamental concept and process in...</td>\n",
       "      <td>Nuclear medicine imaging involves administerin...</td>\n",
       "      <td>1 chapter What Is Nuclear Medicine?A. FUNDAMEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the current applications and global u...</td>\n",
       "      <td>As of 2006, there were roughly 100 different d...</td>\n",
       "      <td>1 chapter What Is Nuclear Medicine?A. FUNDAMEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>photons are emitted. The energy of these gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key components of a gamma camera,...</td>\n",
       "      <td>The key components of a gamma camera are a col...</td>\n",
       "      <td>photons are emitted. The energy of these gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>particular angle. This results in an image wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What is the fundamental concept and process in...   \n",
       "1  What are the current applications and global u...   \n",
       "2  What are the two broad classes of nuclear medi...   \n",
       "3  What are the key components of a gamma camera,...   \n",
       "4  What are the two broad classes of nuclear medi...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  Nuclear medicine imaging involves administerin...   \n",
       "1  As of 2006, there were roughly 100 different d...   \n",
       "2  The two broad classes of nuclear medicine imag...   \n",
       "3  The key components of a gamma camera are a col...   \n",
       "4  The two broad classes of nuclear medicine imag...   \n",
       "\n",
       "                                             Context  \n",
       "0  1 chapter What Is Nuclear Medicine?A. FUNDAMEN...  \n",
       "1  1 chapter What Is Nuclear Medicine?A. FUNDAMEN...  \n",
       "2  photons are emitted. The energy of these gamma...  \n",
       "3  photons are emitted. The energy of these gamma...  \n",
       "4  particular angle. This results in an image wit...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3545695f-646a-4202-9876-b5523d4ca8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-aws\n",
      "  Downloading langchain_aws-0.2.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: boto3>=1.34.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (1.35.54)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (0.3.19)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-aws) (2.9.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.54 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (1.35.54)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.34.131->langchain-aws) (0.10.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.15->langchain-aws) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain-aws) (2.23.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.54->boto3>=1.34.131->langchain-aws) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.54->boto3>=1.34.131->langchain-aws) (2.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-aws) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.54->boto3>=1.34.131->langchain-aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-aws) (1.2.2)\n",
      "Downloading langchain_aws-0.2.7-py3-none-any.whl (87 kB)\n",
      "Installing collected packages: langchain-aws\n",
      "Successfully installed langchain-aws-0.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "866356a1-558b-4536-a866-9979de7cb791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv(\"qa_data.csv\")\n",
    "result_df = pd.read_csv(\"qa_with_mistral_responses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7944f9c-57a6-4148-ae62-5d18c9181520",
   "metadata": {},
   "source": [
    "## Metrics: \n",
    "\n",
    "- `Faithfulness` metric measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. Higher the better.\n",
    "- `FactualCorrectness` is a metric that compares and evaluates the factual accuracy of the generated response with the reference.\n",
    "- `Semantic Similarity` pertains to the assessment of the semantic resemblance between the generated answer and the ground truth. This evaluation is based on the ground truth and the answer, with values falling within the range of 0 to 1. A higher score signifies a better alignment between the generated answer and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e26969db-dc73-4553-9c2f-3c5740c3ffa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 14:12:24,504 - botocore.credentials - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2024-11-20 14:12:24,577 - botocore.credentials - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness, FactualCorrectness, SemanticSimilarity\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# AWS Bedrock configuration\n",
    "config = {\n",
    "    \"llm\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"embeddings\": \"amazon.titan-embed-text-v1\",\n",
    "    \"temperature\": 0.4,\n",
    "}\n",
    "\n",
    "# Initialize Bedrock evaluator models\n",
    "evaluator_llm = LangchainLLMWrapper(ChatBedrockConverse(\n",
    "    model=config[\"llm\"],\n",
    "    temperature=config[\"temperature\"],\n",
    "))\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(BedrockEmbeddings(\n",
    "    model_id=config[\"embeddings\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dd2bc1c-8abe-4bd2-affe-0f78740b59b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f0295885404190a7ccfb5213e1fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 14:12:59,900 - ragas.executor - ERROR - Exception raised in Job[13]: AttributeError('StringIO' object has no attribute 'sentences')\n",
      "2024-11-20 14:15:25,966 - ragas.executor - ERROR - Exception raised in Job[1]: TimeoutError()\n",
      "2024-11-20 14:15:25,967 - ragas.executor - ERROR - Exception raised in Job[4]: TimeoutError()\n",
      "2024-11-20 14:15:25,968 - ragas.executor - ERROR - Exception raised in Job[7]: TimeoutError()\n",
      "2024-11-20 14:15:26,469 - ragas.executor - ERROR - Exception raised in Job[16]: TimeoutError()\n",
      "2024-11-20 14:15:26,832 - ragas.executor - ERROR - Exception raised in Job[19]: TimeoutError()\n",
      "2024-11-20 14:15:32,520 - ragas.executor - ERROR - Exception raised in Job[22]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'factual_correctness': 0.0400, 'faithfulness': 0.0000, 'semantic_similarity': 0.4264}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 14:16:33,823 - urllib3.connectionpool - WARNING - Connection pool is full, discarding connection: bedrock-runtime.us-east-1.amazonaws.com. Connection pool size: 10\n",
      "2024-11-20 14:16:35,571 - urllib3.connectionpool - WARNING - Connection pool is full, discarding connection: bedrock-runtime.us-east-1.amazonaws.com. Connection pool size: 10\n"
     ]
    }
   ],
   "source": [
    "# Create dataset dictionary\n",
    "dataset_dict_1 = {\n",
    "    \"question\": qa_df['Question'].tolist()[:8],\n",
    "    \"answer\": result_df['mistral_response'].tolist()[:8],\n",
    "    \"ground_truth\": qa_df['Answer'].tolist()[:8],\n",
    "    \"retrieved_contexts\": [[context] if isinstance(context, str) else context \n",
    "                         for context in qa_df['Context'].tolist()[:8]]\n",
    "}\n",
    "ragas_dataset_1 = Dataset.from_dict(dataset_dict_1)\n",
    "\n",
    "metrics = [\n",
    "    FactualCorrectness(llm=evaluator_llm), \n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    SemanticSimilarity(embeddings=evaluator_embeddings),\n",
    "]\n",
    "\n",
    "results_mistral = evaluate(\n",
    "    dataset=ragas_dataset_1,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Evaluation Results:\", results_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da21fb2d-c385-4009-a473-2a25f5f3ae1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the fundamental concept and process in...</td>\n",
       "      <td>[1 chapter What Is Nuclear Medicine?A. FUNDAME...</td>\n",
       "      <td>Nanomicroscopy is a technique used to observe ...</td>\n",
       "      <td>Nuclear medicine imaging involves administerin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the current applications and global u...</td>\n",
       "      <td>[1 chapter What Is Nuclear Medicine?A. FUNDAME...</td>\n",
       "      <td>Nanomicrobiology is a branch of biology that u...</td>\n",
       "      <td>As of 2006, there were roughly 100 different d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>[photons are emitted. The energy of these gamm...</td>\n",
       "      <td>1. Imaging of Nuclear Vitamins and Vitamins:\\n...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key components of a gamma camera,...</td>\n",
       "      <td>[photons are emitted. The energy of these gamm...</td>\n",
       "      <td>1. Aperture: The size of the lens at the cente...</td>\n",
       "      <td>The key components of a gamma camera are a col...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>[particular angle. This results in an image wi...</td>\n",
       "      <td>1. Imaging of the MRI MRI MRI MRI MRI MRI MRI ...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the fundamental concept and process in...   \n",
       "1  What are the current applications and global u...   \n",
       "2  What are the two broad classes of nuclear medi...   \n",
       "3  What are the key components of a gamma camera,...   \n",
       "4  What are the two broad classes of nuclear medi...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [1 chapter What Is Nuclear Medicine?A. FUNDAME...   \n",
       "1  [1 chapter What Is Nuclear Medicine?A. FUNDAME...   \n",
       "2  [photons are emitted. The energy of these gamm...   \n",
       "3  [photons are emitted. The energy of these gamm...   \n",
       "4  [particular angle. This results in an image wi...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Nanomicroscopy is a technique used to observe ...   \n",
       "1  Nanomicrobiology is a branch of biology that u...   \n",
       "2  1. Imaging of Nuclear Vitamins and Vitamins:\\n...   \n",
       "3  1. Aperture: The size of the lens at the cente...   \n",
       "4  1. Imaging of the MRI MRI MRI MRI MRI MRI MRI ...   \n",
       "\n",
       "                                           reference  factual_correctness  \\\n",
       "0  Nuclear medicine imaging involves administerin...                  0.0   \n",
       "1  As of 2006, there were roughly 100 different d...                  0.0   \n",
       "2  The two broad classes of nuclear medicine imag...                  0.0   \n",
       "3  The key components of a gamma camera are a col...                  0.0   \n",
       "4  The two broad classes of nuclear medicine imag...                  0.0   \n",
       "\n",
       "   faithfulness  semantic_similarity  \n",
       "0           NaN             0.219188  \n",
       "1           0.0             0.211713  \n",
       "2           0.0             0.553157  \n",
       "3           0.0             0.313325  \n",
       "4           NaN             0.314468  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mistral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db24c59e-cc8f-4e39-b7b6-2c73a1d2cd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c41047894340ab9c65f7aac46c67b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'factual_correctness': 1.0000, 'faithfulness': 0.9643, 'semantic_similarity': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "# Create dataset dictionary\n",
    "dataset_dict_2 = {\n",
    "    \"question\": qa_df['Question'].tolist()[:8],\n",
    "    \"answer\": qa_df['Answer'].tolist()[:8],\n",
    "    \"ground_truth\": qa_df['Answer'].tolist()[:8],\n",
    "    \"retrieved_contexts\": [[context] if isinstance(context, str) else context \n",
    "                         for context in qa_df['Context'].tolist()[:8]]\n",
    "}\n",
    "ragas_dataset_2 = Dataset.from_dict(dataset_dict_2)\n",
    "\n",
    "metrics = [\n",
    "    FactualCorrectness(llm=evaluator_llm), \n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    SemanticSimilarity(embeddings=evaluator_embeddings)\n",
    "]\n",
    "\n",
    "results_claude = evaluate(\n",
    "    dataset=ragas_dataset_2,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0ec144d-3a00-47f8-b545-2a435260378a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the fundamental concept and process in...</td>\n",
       "      <td>[1 chapter What Is Nuclear Medicine?A. FUNDAME...</td>\n",
       "      <td>Nuclear medicine imaging involves administerin...</td>\n",
       "      <td>Nuclear medicine imaging involves administerin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the current applications and global u...</td>\n",
       "      <td>[1 chapter What Is Nuclear Medicine?A. FUNDAME...</td>\n",
       "      <td>As of 2006, there were roughly 100 different d...</td>\n",
       "      <td>As of 2006, there were roughly 100 different d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>[photons are emitted. The energy of these gamm...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key components of a gamma camera,...</td>\n",
       "      <td>[photons are emitted. The energy of these gamm...</td>\n",
       "      <td>The key components of a gamma camera are a col...</td>\n",
       "      <td>The key components of a gamma camera are a col...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the two broad classes of nuclear medi...</td>\n",
       "      <td>[particular angle. This results in an image wi...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>The two broad classes of nuclear medicine imag...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the fundamental concept and process in...   \n",
       "1  What are the current applications and global u...   \n",
       "2  What are the two broad classes of nuclear medi...   \n",
       "3  What are the key components of a gamma camera,...   \n",
       "4  What are the two broad classes of nuclear medi...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [1 chapter What Is Nuclear Medicine?A. FUNDAME...   \n",
       "1  [1 chapter What Is Nuclear Medicine?A. FUNDAME...   \n",
       "2  [photons are emitted. The energy of these gamm...   \n",
       "3  [photons are emitted. The energy of these gamm...   \n",
       "4  [particular angle. This results in an image wi...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Nuclear medicine imaging involves administerin...   \n",
       "1  As of 2006, there were roughly 100 different d...   \n",
       "2  The two broad classes of nuclear medicine imag...   \n",
       "3  The key components of a gamma camera are a col...   \n",
       "4  The two broad classes of nuclear medicine imag...   \n",
       "\n",
       "                                           reference  factual_correctness  \\\n",
       "0  Nuclear medicine imaging involves administerin...                  1.0   \n",
       "1  As of 2006, there were roughly 100 different d...                  1.0   \n",
       "2  The two broad classes of nuclear medicine imag...                  1.0   \n",
       "3  The key components of a gamma camera are a col...                  1.0   \n",
       "4  The two broad classes of nuclear medicine imag...                  1.0   \n",
       "\n",
       "   faithfulness  semantic_similarity  \n",
       "0      1.000000                  1.0  \n",
       "1      1.000000                  1.0  \n",
       "2      0.888889                  1.0  \n",
       "3      0.909091                  1.0  \n",
       "4      1.000000                  1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_claude.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa7fcf-eabe-4311-aadd-dc6f5f728748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analysis(mistral_df, claude_df):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "    \n",
    "    for i, col in enumerate(mistral_df.columns):\n",
    "        sns.kdeplot(\n",
    "            data=[mistral_df[col].values, claude_df[col].values],\n",
    "            legend=False,\n",
    "            ax=axs[i],\n",
    "            fill=True\n",
    "        )\n",
    "        axs[i].set_title(f'{col} scores distribution')\n",
    "        axs[i].legend(labels=[\"mistral\", \"claude\"])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the analysis function\n",
    "analysis(\n",
    "    results_mistral[['factual_correctness', 'faithfulness', 'semantic_similarity']],\n",
    "    results_mistral[['factual_correctness', 'faithfulness', 'semantic_similarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048e7c7-7f6c-4fc7-aa9c-34bbeb2d6037",
   "metadata": {},
   "source": [
    "Obviously the results of comparing claude answers to claude answers will be perfect, this is just to test if the evaluation is working correctly. After, we will fill tune the mistral model and check again! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59154cc6-d122-4b5a-9a75-67d8e4614f6e",
   "metadata": {},
   "source": [
    "## Fine tune using PEFT - LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890f04-c3f1-4c67-938a-9dce3c2c2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
